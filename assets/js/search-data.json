{
  
    
        "post0": {
            "title": "Interactive Dashboard",
            "content": "PhDs Awarded in the US . By: Dapo Adegbile . In this blog post I will be examining how many and the types of Doctorates given out in the United States in 2017. The data is originally taken from: https://ncses.nsf.gov/pubs/nsf19301/data. I cleaned the dataset and perfomed some analysis using pandas , and I then made a dashboard to better visualize key insights from the data in plotly and Streamlit. . I chose to use Plotly as I am already familar with it&#39;s visualizations and I choose to use streamlit to deploy the dashboard because of the ease of use and the sleak display of the dashboard. . Data Cleaning . My data cleaning process can be found below: . import pandas as pd import numpy as np . state_names = [&quot;Alaska&quot;, &quot;Alabama&quot;, &quot;Arkansas&quot;, &quot;Arizona&quot;, &quot;California&quot;, &quot;Colorado&quot;, &quot;Connecticut&quot;, &quot;District of Columbia&quot;, &quot;Delaware&quot;, &quot;Florida&quot;, &quot;Georgia&quot;, &quot;Hawaii&quot;, &quot;Iowa&quot;, &quot;Idaho&quot;, &quot;Illinois&quot;, &quot;Indiana&quot;, &quot;Kansas&quot;, &quot;Kentucky&quot;, &quot;Louisiana&quot;, &quot;Massachusetts&quot;, &quot;Maryland&quot;, &quot;Maine&quot;, &quot;Michigan&quot;, &quot;Minnesota&quot;, &quot;Missouri&quot;, &quot;Mississippi&quot;, &quot;Montana&quot;, &quot;North Carolina&quot;, &quot;North Dakota&quot;, &quot;Nebraska&quot;, &quot;New Hampshire&quot;, &quot;New Jersey&quot;, &quot;New Mexico&quot;, &quot;Nevada&quot;, &quot;New York&quot;, &quot;Ohio&quot;, &quot;Oklahoma&quot;, &quot;Oregon&quot;, &quot;Pennsylvania&quot;, &quot;Puerto Rico&quot;, &quot;Rhode Island&quot;, &quot;South Carolina&quot;, &quot;South Dakota&quot;, &quot;Tennessee&quot;, &quot;Texas&quot;, &quot;Utah&quot;, &quot;Virginia&quot;, &quot;Vermont&quot;, &quot;Washington&quot;, &quot;Wisconsin&quot;, &quot;West Virginia&quot;, &quot;Wyoming&quot;] . df = pd.read_excel(&quot;/Users/dapoadegbile/Documents/data_tables/sed17-sr-tab007.xlsx&quot;, header = 4) . /Users/dapoadegbile/opt/anaconda3/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:214: UserWarning: Workbook contains no default style, apply openpyxl&#39;s default . df1 = df.set_index(df.iloc[:,0]) . df1.iloc[:,0].value_counts . &lt;bound method IndexOpsMixin.value_counts of Unnamed: 0 NaN NaN All institutions All institutions Alabama Alabama Alabama A&amp;M U. Alabama A&amp;M U. Alabama State U. Alabama State U. ... Medical C. Wisconsin Medical C. Wisconsin U. Wisconsin-Madison U. Wisconsin-Madison U. Wisconsin-Milwaukee U. Wisconsin-Milwaukee Wyoming Wyoming U. Wyoming U. Wyoming Name: Unnamed: 0, Length: 482, dtype: object&gt; . df1 = df1.loc[state_names] . Unnamed: 0 Unnamed: 1 Life sciences Unnamed: 3 Unnamed: 4 Unnamed: 5 Physical sciences and earth sciences Unnamed: 7 Unnamed: 8 Unnamed: 9 ... Unnamed: 20 Unnamed: 21 Unnamed: 22 Unnamed: 23 Unnamed: 24 Unnamed: 25 Unnamed: 26 Unnamed: 27 Unnamed: 28 Unnamed: 29 . Unnamed: 0 . Alaska Alaska | 52.0 | 10.0 | 4.0 | 6.0 | 0.0 | 20.0 | 2.0 | 15.0 | 3.0 | ... | 3.0 | 0.0 | 0.0 | 0.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . Alabama Alabama | 707.0 | 188.0 | 32.0 | 122.0 | 34.0 | 59.0 | 23.0 | 7.0 | 29.0 | ... | 131.0 | 5.0 | 4.0 | 14.0 | 17.0 | 22.0 | 6.0 | 13.0 | 18.0 | 32.0 | . Arkansas Arkansas | 202.0 | 75.0 | 18.0 | 35.0 | 22.0 | 17.0 | 11.0 | 1.0 | 5.0 | ... | 33.0 | 0.0 | 4.0 | 2.0 | 4.0 | 7.0 | 4.0 | 2.0 | 1.0 | 9.0 | . Arizona Arizona | 801.0 | 133.0 | 23.0 | 74.0 | 36.0 | 110.0 | 31.0 | 29.0 | 50.0 | ... | 141.0 | 2.0 | 10.0 | 8.0 | 10.0 | 50.0 | 6.0 | 12.0 | 12.0 | 31.0 | . California California | 6105.0 | 1300.0 | 111.0 | 1015.0 | 174.0 | 841.0 | 367.0 | 178.0 | 296.0 | ... | 1151.0 | 38.0 | 166.0 | 97.0 | 57.0 | 269.0 | 10.0 | 164.0 | 153.0 | 197.0 | . Colorado Colorado | 1005.0 | 212.0 | 25.0 | 162.0 | 25.0 | 155.0 | 42.0 | 47.0 | 66.0 | ... | 206.0 | 22.0 | 8.0 | 14.0 | 39.0 | 29.0 | 0.0 | 12.0 | 29.0 | 53.0 | . Connecticut Connecticut | 748.0 | 196.0 | 14.0 | 155.0 | 27.0 | 104.0 | 56.0 | 15.0 | 33.0 | ... | 97.0 | 0.0 | 18.0 | 12.0 | 3.0 | 17.0 | 0.0 | 10.0 | 18.0 | 19.0 | . District of Columbia District of Columbia | 623.0 | 55.0 | 0.0 | 50.0 | 5.0 | 37.0 | 19.0 | 6.0 | 12.0 | ... | 78.0 | 0.0 | 3.0 | 0.0 | 4.0 | 5.0 | 0.0 | 1.0 | 10.0 | 55.0 | . Delaware Delaware | 238.0 | 59.0 | 9.0 | 40.0 | 10.0 | 24.0 | 2.0 | 11.0 | 11.0 | ... | 69.0 | 0.0 | 0.0 | 27.0 | 13.0 | 7.0 | 0.0 | 11.0 | 8.0 | 3.0 | . Florida Florida | 2336.0 | 490.0 | 77.0 | 285.0 | 128.0 | 259.0 | 94.0 | 64.0 | 101.0 | ... | 419.0 | 21.0 | 26.0 | 29.0 | 45.0 | 78.0 | 23.0 | 48.0 | 51.0 | 98.0 | . Georgia Georgia | 1492.0 | 357.0 | 40.0 | 261.0 | 56.0 | 129.0 | 72.0 | 12.0 | 45.0 | ... | 360.0 | 46.0 | 37.0 | 35.0 | 19.0 | 80.0 | 8.0 | 25.0 | 51.0 | 59.0 | . Hawaii Hawaii | 189.0 | 44.0 | 6.0 | 26.0 | 12.0 | 29.0 | 2.0 | 21.0 | 6.0 | ... | 11.0 | 0.0 | 0.0 | 0.0 | 2.0 | 7.0 | 0.0 | 0.0 | 2.0 | 0.0 | . Iowa Iowa | 715.0 | 150.0 | 31.0 | 90.0 | 29.0 | 79.0 | 45.0 | 10.0 | 24.0 | ... | 152.0 | 10.0 | 14.0 | 8.0 | 14.0 | 27.0 | 7.0 | 6.0 | 30.0 | 36.0 | . Idaho Idaho | 103.0 | 32.0 | 12.0 | 15.0 | 5.0 | 14.0 | 2.0 | 9.0 | 3.0 | ... | 16.0 | 0.0 | 1.0 | 0.0 | 1.0 | 4.0 | 0.0 | 5.0 | 1.0 | 4.0 | . Illinois Illinois | 2534.0 | 478.0 | 49.0 | 340.0 | 89.0 | 267.0 | 133.0 | 19.0 | 115.0 | ... | 435.0 | 13.0 | 41.0 | 39.0 | 35.0 | 91.0 | 9.0 | 66.0 | 53.0 | 88.0 | . Indiana Indiana | 1572.0 | 309.0 | 60.0 | 204.0 | 45.0 | 195.0 | 115.0 | 15.0 | 65.0 | ... | 329.0 | 38.0 | 17.0 | 31.0 | 32.0 | 56.0 | 9.0 | 15.0 | 57.0 | 74.0 | . Kansas Kansas | 530.0 | 148.0 | 42.0 | 75.0 | 31.0 | 44.0 | 33.0 | 3.0 | 8.0 | ... | 74.0 | 3.0 | 6.0 | 10.0 | 11.0 | 13.0 | 13.0 | 1.0 | 8.0 | 9.0 | . Kentucky Kentucky | 497.0 | 138.0 | 15.0 | 82.0 | 41.0 | 22.0 | 13.0 | 1.0 | 8.0 | ... | 48.0 | 0.0 | 2.0 | 10.0 | 9.0 | 9.0 | 3.0 | 6.0 | 3.0 | 6.0 | . Louisiana Louisiana | 607.0 | 157.0 | 27.0 | 98.0 | 32.0 | 68.0 | 41.0 | 12.0 | 15.0 | ... | 74.0 | 0.0 | 5.0 | 7.0 | 6.0 | 5.0 | 0.0 | 4.0 | 7.0 | 40.0 | . Massachusetts Massachusetts | 2879.0 | 706.0 | 57.0 | 510.0 | 139.0 | 372.0 | 126.0 | 78.0 | 168.0 | ... | 597.0 | 20.0 | 74.0 | 53.0 | 16.0 | 85.0 | 7.0 | 54.0 | 102.0 | 186.0 | . Maryland Maryland | 1295.0 | 439.0 | 32.0 | 279.0 | 128.0 | 141.0 | 40.0 | 34.0 | 67.0 | ... | 225.0 | 7.0 | 49.0 | 13.0 | 19.0 | 47.0 | 0.0 | 20.0 | 35.0 | 35.0 | . Maine Maine | 56.0 | 15.0 | 4.0 | 11.0 | 0.0 | 11.0 | 0.0 | 9.0 | 2.0 | ... | 11.0 | 0.0 | 1.0 | 1.0 | 0.0 | 2.0 | 0.0 | 1.0 | 3.0 | 3.0 | . Michigan Michigan | 1906.0 | 385.0 | 51.0 | 257.0 | 77.0 | 206.0 | 98.0 | 25.0 | 83.0 | ... | 394.0 | 17.0 | 28.0 | 32.0 | 22.0 | 90.0 | 9.0 | 35.0 | 75.0 | 86.0 | . Minnesota Minnesota | 1374.0 | 397.0 | 50.0 | 145.0 | 202.0 | 66.0 | 38.0 | 12.0 | 16.0 | ... | 128.0 | 11.0 | 19.0 | 23.0 | 8.0 | 30.0 | 1.0 | 7.0 | 21.0 | 8.0 | . Missouri Missouri | 1022.0 | 259.0 | 34.0 | 190.0 | 35.0 | 108.0 | 49.0 | 28.0 | 31.0 | ... | 171.0 | 4.0 | 26.0 | 9.0 | 16.0 | 26.0 | 2.0 | 9.0 | 29.0 | 50.0 | . Mississippi Mississippi | 460.0 | 107.0 | 27.0 | 41.0 | 39.0 | 48.0 | 32.0 | 8.0 | 8.0 | ... | 51.0 | 2.0 | 2.0 | 3.0 | 8.0 | 5.0 | 4.0 | 5.0 | 6.0 | 16.0 | . Montana Montana | 119.0 | 36.0 | 9.0 | 27.0 | 0.0 | 15.0 | 7.0 | 2.0 | 6.0 | ... | 9.0 | 0.0 | 2.0 | 0.0 | 0.0 | 2.0 | 0.0 | 1.0 | 1.0 | 3.0 | . North Carolina North Carolina | 1833.0 | 545.0 | 73.0 | 369.0 | 103.0 | 194.0 | 101.0 | 49.0 | 44.0 | ... | 316.0 | 7.0 | 47.0 | 28.0 | 18.0 | 58.0 | 14.0 | 29.0 | 40.0 | 75.0 | . North Dakota North Dakota | 181.0 | 46.0 | 16.0 | 21.0 | 9.0 | 10.0 | 6.0 | 1.0 | 3.0 | ... | 30.0 | 3.0 | 1.0 | 2.0 | 6.0 | 4.0 | 0.0 | 3.0 | 1.0 | 10.0 | . Nebraska Nebraska | 363.0 | 143.0 | 36.0 | 80.0 | 27.0 | 32.0 | 19.0 | 6.0 | 7.0 | ... | 44.0 | 0.0 | 6.0 | 2.0 | 4.0 | 8.0 | 0.0 | 4.0 | 12.0 | 8.0 | . New Hampshire New Hampshire | 158.0 | 60.0 | 9.0 | 50.0 | 1.0 | 32.0 | 11.0 | 5.0 | 16.0 | ... | 17.0 | 0.0 | 2.0 | 1.0 | 2.0 | 1.0 | 0.0 | 3.0 | 2.0 | 6.0 | . New Jersey New Jersey | 1115.0 | 209.0 | 26.0 | 160.0 | 23.0 | 145.0 | 62.0 | 28.0 | 55.0 | ... | 194.0 | 3.0 | 24.0 | 19.0 | 11.0 | 39.0 | 8.0 | 13.0 | 32.0 | 45.0 | . New Mexico New Mexico | 299.0 | 45.0 | 6.0 | 31.0 | 8.0 | 44.0 | 9.0 | 11.0 | 24.0 | ... | 74.0 | 0.0 | 2.0 | 10.0 | 5.0 | 16.0 | 5.0 | 7.0 | 5.0 | 24.0 | . Nevada Nevada | 200.0 | 21.0 | 4.0 | 11.0 | 6.0 | 20.0 | 11.0 | 4.0 | 5.0 | ... | 34.0 | 0.0 | 1.0 | 4.0 | 6.0 | 3.0 | 0.0 | 4.0 | 6.0 | 10.0 | . New York New York | 4064.0 | 859.0 | 68.0 | 677.0 | 114.0 | 411.0 | 164.0 | 63.0 | 184.0 | ... | 567.0 | 14.0 | 81.0 | 68.0 | 35.0 | 112.0 | 12.0 | 57.0 | 74.0 | 114.0 | . Ohio Ohio | 2028.0 | 440.0 | 46.0 | 314.0 | 80.0 | 260.0 | 141.0 | 14.0 | 105.0 | ... | 410.0 | 23.0 | 40.0 | 35.0 | 15.0 | 77.0 | 7.0 | 47.0 | 61.0 | 105.0 | . Oklahoma Oklahoma | 524.0 | 137.0 | 28.0 | 86.0 | 23.0 | 46.0 | 16.0 | 17.0 | 13.0 | ... | 70.0 | 3.0 | 5.0 | 7.0 | 7.0 | 15.0 | 4.0 | 0.0 | 10.0 | 19.0 | . Oregon Oregon | 572.0 | 183.0 | 54.0 | 104.0 | 25.0 | 95.0 | 40.0 | 28.0 | 27.0 | ... | 71.0 | 0.0 | 4.0 | 5.0 | 8.0 | 16.0 | 6.0 | 6.0 | 6.0 | 20.0 | . Pennsylvania Pennsylvania | 2628.0 | 589.0 | 43.0 | 416.0 | 130.0 | 248.0 | 124.0 | 33.0 | 91.0 | ... | 545.0 | 10.0 | 64.0 | 60.0 | 27.0 | 80.0 | 15.0 | 68.0 | 85.0 | 136.0 | . Puerto Rico Puerto Rico | 84.0 | 8.0 | 2.0 | 6.0 | 0.0 | 4.0 | 2.0 | 1.0 | 1.0 | ... | 4.0 | 0.0 | 0.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . Rhode Island Rhode Island | 322.0 | 67.0 | 3.0 | 55.0 | 9.0 | 47.0 | 12.0 | 22.0 | 13.0 | ... | 39.0 | 0.0 | 5.0 | 3.0 | 0.0 | 8.0 | 2.0 | 5.0 | 7.0 | 9.0 | . South Carolina South Carolina | 506.0 | 100.0 | 8.0 | 57.0 | 35.0 | 59.0 | 38.0 | 7.0 | 14.0 | ... | 141.0 | 0.0 | 17.0 | 19.0 | 24.0 | 22.0 | 6.0 | 6.0 | 31.0 | 16.0 | . South Dakota South Dakota | 110.0 | 37.0 | 21.0 | 13.0 | 3.0 | 12.0 | 8.0 | 4.0 | 0.0 | ... | 21.0 | 0.0 | 0.0 | 6.0 | 0.0 | 5.0 | 0.0 | 5.0 | 2.0 | 3.0 | . Tennessee Tennessee | 1032.0 | 270.0 | 22.0 | 186.0 | 62.0 | 87.0 | 51.0 | 7.0 | 29.0 | ... | 185.0 | 3.0 | 19.0 | 19.0 | 7.0 | 41.0 | 8.0 | 20.0 | 11.0 | 57.0 | . Texas Texas | 4068.0 | 905.0 | 99.0 | 609.0 | 197.0 | 424.0 | 177.0 | 101.0 | 146.0 | ... | 880.0 | 34.0 | 77.0 | 92.0 | 84.0 | 184.0 | 23.0 | 91.0 | 114.0 | 181.0 | . Utah Utah | 508.0 | 116.0 | 8.0 | 85.0 | 23.0 | 54.0 | 27.0 | 13.0 | 14.0 | ... | 99.0 | 1.0 | 15.0 | 12.0 | 12.0 | 15.0 | 0.0 | 6.0 | 16.0 | 22.0 | . Virginia Virginia | 1513.0 | 265.0 | 51.0 | 157.0 | 57.0 | 145.0 | 56.0 | 29.0 | 60.0 | ... | 291.0 | 11.0 | 22.0 | 13.0 | 33.0 | 63.0 | 6.0 | 21.0 | 43.0 | 79.0 | . Vermont Vermont | 61.0 | 25.0 | 9.0 | 15.0 | 1.0 | 6.0 | 6.0 | 0.0 | 0.0 | ... | 7.0 | 0.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 3.0 | . Washington Washington | 914.0 | 256.0 | 51.0 | 143.0 | 62.0 | 110.0 | 49.0 | 24.0 | 37.0 | ... | 171.0 | 5.0 | 24.0 | 24.0 | 10.0 | 27.0 | 3.0 | 12.0 | 26.0 | 40.0 | . Wisconsin Wisconsin | 1130.0 | 311.0 | 51.0 | 183.0 | 77.0 | 121.0 | 60.0 | 18.0 | 43.0 | ... | 176.0 | 0.0 | 19.0 | 17.0 | 13.0 | 37.0 | 9.0 | 16.0 | 31.0 | 34.0 | . West Virginia West Virginia | 183.0 | 52.0 | 10.0 | 29.0 | 13.0 | 17.0 | 7.0 | 2.0 | 8.0 | ... | 32.0 | 2.0 | 0.0 | 5.0 | 2.0 | 4.0 | 4.0 | 2.0 | 6.0 | 7.0 | . Wyoming Wyoming | 101.0 | 28.0 | 3.0 | 25.0 | 0.0 | 18.0 | 7.0 | 7.0 | 4.0 | ... | 12.0 | 0.0 | 0.0 | 5.0 | 0.0 | 2.0 | 0.0 | 0.0 | 3.0 | 2.0 | . 52 rows × 30 columns . df1.reset_index(drop = True, inplace = True) . Unnamed: 0 Unnamed: 1 Life sciences Unnamed: 3 Unnamed: 4 Unnamed: 5 Physical sciences and earth sciences Unnamed: 7 Unnamed: 8 Unnamed: 9 ... Unnamed: 20 Unnamed: 21 Unnamed: 22 Unnamed: 23 Unnamed: 24 Unnamed: 25 Unnamed: 26 Unnamed: 27 Unnamed: 28 Unnamed: 29 . 0 Alaska | 52.0 | 10.0 | 4.0 | 6.0 | 0.0 | 20.0 | 2.0 | 15.0 | 3.0 | ... | 3.0 | 0.0 | 0.0 | 0.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 1 Alabama | 707.0 | 188.0 | 32.0 | 122.0 | 34.0 | 59.0 | 23.0 | 7.0 | 29.0 | ... | 131.0 | 5.0 | 4.0 | 14.0 | 17.0 | 22.0 | 6.0 | 13.0 | 18.0 | 32.0 | . 2 Arkansas | 202.0 | 75.0 | 18.0 | 35.0 | 22.0 | 17.0 | 11.0 | 1.0 | 5.0 | ... | 33.0 | 0.0 | 4.0 | 2.0 | 4.0 | 7.0 | 4.0 | 2.0 | 1.0 | 9.0 | . 3 Arizona | 801.0 | 133.0 | 23.0 | 74.0 | 36.0 | 110.0 | 31.0 | 29.0 | 50.0 | ... | 141.0 | 2.0 | 10.0 | 8.0 | 10.0 | 50.0 | 6.0 | 12.0 | 12.0 | 31.0 | . 4 California | 6105.0 | 1300.0 | 111.0 | 1015.0 | 174.0 | 841.0 | 367.0 | 178.0 | 296.0 | ... | 1151.0 | 38.0 | 166.0 | 97.0 | 57.0 | 269.0 | 10.0 | 164.0 | 153.0 | 197.0 | . 5 Colorado | 1005.0 | 212.0 | 25.0 | 162.0 | 25.0 | 155.0 | 42.0 | 47.0 | 66.0 | ... | 206.0 | 22.0 | 8.0 | 14.0 | 39.0 | 29.0 | 0.0 | 12.0 | 29.0 | 53.0 | . 6 Connecticut | 748.0 | 196.0 | 14.0 | 155.0 | 27.0 | 104.0 | 56.0 | 15.0 | 33.0 | ... | 97.0 | 0.0 | 18.0 | 12.0 | 3.0 | 17.0 | 0.0 | 10.0 | 18.0 | 19.0 | . 7 District of Columbia | 623.0 | 55.0 | 0.0 | 50.0 | 5.0 | 37.0 | 19.0 | 6.0 | 12.0 | ... | 78.0 | 0.0 | 3.0 | 0.0 | 4.0 | 5.0 | 0.0 | 1.0 | 10.0 | 55.0 | . 8 Delaware | 238.0 | 59.0 | 9.0 | 40.0 | 10.0 | 24.0 | 2.0 | 11.0 | 11.0 | ... | 69.0 | 0.0 | 0.0 | 27.0 | 13.0 | 7.0 | 0.0 | 11.0 | 8.0 | 3.0 | . 9 Florida | 2336.0 | 490.0 | 77.0 | 285.0 | 128.0 | 259.0 | 94.0 | 64.0 | 101.0 | ... | 419.0 | 21.0 | 26.0 | 29.0 | 45.0 | 78.0 | 23.0 | 48.0 | 51.0 | 98.0 | . 10 Georgia | 1492.0 | 357.0 | 40.0 | 261.0 | 56.0 | 129.0 | 72.0 | 12.0 | 45.0 | ... | 360.0 | 46.0 | 37.0 | 35.0 | 19.0 | 80.0 | 8.0 | 25.0 | 51.0 | 59.0 | . 11 Hawaii | 189.0 | 44.0 | 6.0 | 26.0 | 12.0 | 29.0 | 2.0 | 21.0 | 6.0 | ... | 11.0 | 0.0 | 0.0 | 0.0 | 2.0 | 7.0 | 0.0 | 0.0 | 2.0 | 0.0 | . 12 Iowa | 715.0 | 150.0 | 31.0 | 90.0 | 29.0 | 79.0 | 45.0 | 10.0 | 24.0 | ... | 152.0 | 10.0 | 14.0 | 8.0 | 14.0 | 27.0 | 7.0 | 6.0 | 30.0 | 36.0 | . 13 Idaho | 103.0 | 32.0 | 12.0 | 15.0 | 5.0 | 14.0 | 2.0 | 9.0 | 3.0 | ... | 16.0 | 0.0 | 1.0 | 0.0 | 1.0 | 4.0 | 0.0 | 5.0 | 1.0 | 4.0 | . 14 Illinois | 2534.0 | 478.0 | 49.0 | 340.0 | 89.0 | 267.0 | 133.0 | 19.0 | 115.0 | ... | 435.0 | 13.0 | 41.0 | 39.0 | 35.0 | 91.0 | 9.0 | 66.0 | 53.0 | 88.0 | . 15 Indiana | 1572.0 | 309.0 | 60.0 | 204.0 | 45.0 | 195.0 | 115.0 | 15.0 | 65.0 | ... | 329.0 | 38.0 | 17.0 | 31.0 | 32.0 | 56.0 | 9.0 | 15.0 | 57.0 | 74.0 | . 16 Kansas | 530.0 | 148.0 | 42.0 | 75.0 | 31.0 | 44.0 | 33.0 | 3.0 | 8.0 | ... | 74.0 | 3.0 | 6.0 | 10.0 | 11.0 | 13.0 | 13.0 | 1.0 | 8.0 | 9.0 | . 17 Kentucky | 497.0 | 138.0 | 15.0 | 82.0 | 41.0 | 22.0 | 13.0 | 1.0 | 8.0 | ... | 48.0 | 0.0 | 2.0 | 10.0 | 9.0 | 9.0 | 3.0 | 6.0 | 3.0 | 6.0 | . 18 Louisiana | 607.0 | 157.0 | 27.0 | 98.0 | 32.0 | 68.0 | 41.0 | 12.0 | 15.0 | ... | 74.0 | 0.0 | 5.0 | 7.0 | 6.0 | 5.0 | 0.0 | 4.0 | 7.0 | 40.0 | . 19 Massachusetts | 2879.0 | 706.0 | 57.0 | 510.0 | 139.0 | 372.0 | 126.0 | 78.0 | 168.0 | ... | 597.0 | 20.0 | 74.0 | 53.0 | 16.0 | 85.0 | 7.0 | 54.0 | 102.0 | 186.0 | . 20 Maryland | 1295.0 | 439.0 | 32.0 | 279.0 | 128.0 | 141.0 | 40.0 | 34.0 | 67.0 | ... | 225.0 | 7.0 | 49.0 | 13.0 | 19.0 | 47.0 | 0.0 | 20.0 | 35.0 | 35.0 | . 21 Maine | 56.0 | 15.0 | 4.0 | 11.0 | 0.0 | 11.0 | 0.0 | 9.0 | 2.0 | ... | 11.0 | 0.0 | 1.0 | 1.0 | 0.0 | 2.0 | 0.0 | 1.0 | 3.0 | 3.0 | . 22 Michigan | 1906.0 | 385.0 | 51.0 | 257.0 | 77.0 | 206.0 | 98.0 | 25.0 | 83.0 | ... | 394.0 | 17.0 | 28.0 | 32.0 | 22.0 | 90.0 | 9.0 | 35.0 | 75.0 | 86.0 | . 23 Minnesota | 1374.0 | 397.0 | 50.0 | 145.0 | 202.0 | 66.0 | 38.0 | 12.0 | 16.0 | ... | 128.0 | 11.0 | 19.0 | 23.0 | 8.0 | 30.0 | 1.0 | 7.0 | 21.0 | 8.0 | . 24 Missouri | 1022.0 | 259.0 | 34.0 | 190.0 | 35.0 | 108.0 | 49.0 | 28.0 | 31.0 | ... | 171.0 | 4.0 | 26.0 | 9.0 | 16.0 | 26.0 | 2.0 | 9.0 | 29.0 | 50.0 | . 25 Mississippi | 460.0 | 107.0 | 27.0 | 41.0 | 39.0 | 48.0 | 32.0 | 8.0 | 8.0 | ... | 51.0 | 2.0 | 2.0 | 3.0 | 8.0 | 5.0 | 4.0 | 5.0 | 6.0 | 16.0 | . 26 Montana | 119.0 | 36.0 | 9.0 | 27.0 | 0.0 | 15.0 | 7.0 | 2.0 | 6.0 | ... | 9.0 | 0.0 | 2.0 | 0.0 | 0.0 | 2.0 | 0.0 | 1.0 | 1.0 | 3.0 | . 27 North Carolina | 1833.0 | 545.0 | 73.0 | 369.0 | 103.0 | 194.0 | 101.0 | 49.0 | 44.0 | ... | 316.0 | 7.0 | 47.0 | 28.0 | 18.0 | 58.0 | 14.0 | 29.0 | 40.0 | 75.0 | . 28 North Dakota | 181.0 | 46.0 | 16.0 | 21.0 | 9.0 | 10.0 | 6.0 | 1.0 | 3.0 | ... | 30.0 | 3.0 | 1.0 | 2.0 | 6.0 | 4.0 | 0.0 | 3.0 | 1.0 | 10.0 | . 29 Nebraska | 363.0 | 143.0 | 36.0 | 80.0 | 27.0 | 32.0 | 19.0 | 6.0 | 7.0 | ... | 44.0 | 0.0 | 6.0 | 2.0 | 4.0 | 8.0 | 0.0 | 4.0 | 12.0 | 8.0 | . 30 New Hampshire | 158.0 | 60.0 | 9.0 | 50.0 | 1.0 | 32.0 | 11.0 | 5.0 | 16.0 | ... | 17.0 | 0.0 | 2.0 | 1.0 | 2.0 | 1.0 | 0.0 | 3.0 | 2.0 | 6.0 | . 31 New Jersey | 1115.0 | 209.0 | 26.0 | 160.0 | 23.0 | 145.0 | 62.0 | 28.0 | 55.0 | ... | 194.0 | 3.0 | 24.0 | 19.0 | 11.0 | 39.0 | 8.0 | 13.0 | 32.0 | 45.0 | . 32 New Mexico | 299.0 | 45.0 | 6.0 | 31.0 | 8.0 | 44.0 | 9.0 | 11.0 | 24.0 | ... | 74.0 | 0.0 | 2.0 | 10.0 | 5.0 | 16.0 | 5.0 | 7.0 | 5.0 | 24.0 | . 33 Nevada | 200.0 | 21.0 | 4.0 | 11.0 | 6.0 | 20.0 | 11.0 | 4.0 | 5.0 | ... | 34.0 | 0.0 | 1.0 | 4.0 | 6.0 | 3.0 | 0.0 | 4.0 | 6.0 | 10.0 | . 34 New York | 4064.0 | 859.0 | 68.0 | 677.0 | 114.0 | 411.0 | 164.0 | 63.0 | 184.0 | ... | 567.0 | 14.0 | 81.0 | 68.0 | 35.0 | 112.0 | 12.0 | 57.0 | 74.0 | 114.0 | . 35 Ohio | 2028.0 | 440.0 | 46.0 | 314.0 | 80.0 | 260.0 | 141.0 | 14.0 | 105.0 | ... | 410.0 | 23.0 | 40.0 | 35.0 | 15.0 | 77.0 | 7.0 | 47.0 | 61.0 | 105.0 | . 36 Oklahoma | 524.0 | 137.0 | 28.0 | 86.0 | 23.0 | 46.0 | 16.0 | 17.0 | 13.0 | ... | 70.0 | 3.0 | 5.0 | 7.0 | 7.0 | 15.0 | 4.0 | 0.0 | 10.0 | 19.0 | . 37 Oregon | 572.0 | 183.0 | 54.0 | 104.0 | 25.0 | 95.0 | 40.0 | 28.0 | 27.0 | ... | 71.0 | 0.0 | 4.0 | 5.0 | 8.0 | 16.0 | 6.0 | 6.0 | 6.0 | 20.0 | . 38 Pennsylvania | 2628.0 | 589.0 | 43.0 | 416.0 | 130.0 | 248.0 | 124.0 | 33.0 | 91.0 | ... | 545.0 | 10.0 | 64.0 | 60.0 | 27.0 | 80.0 | 15.0 | 68.0 | 85.0 | 136.0 | . 39 Puerto Rico | 84.0 | 8.0 | 2.0 | 6.0 | 0.0 | 4.0 | 2.0 | 1.0 | 1.0 | ... | 4.0 | 0.0 | 0.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 40 Rhode Island | 322.0 | 67.0 | 3.0 | 55.0 | 9.0 | 47.0 | 12.0 | 22.0 | 13.0 | ... | 39.0 | 0.0 | 5.0 | 3.0 | 0.0 | 8.0 | 2.0 | 5.0 | 7.0 | 9.0 | . 41 South Carolina | 506.0 | 100.0 | 8.0 | 57.0 | 35.0 | 59.0 | 38.0 | 7.0 | 14.0 | ... | 141.0 | 0.0 | 17.0 | 19.0 | 24.0 | 22.0 | 6.0 | 6.0 | 31.0 | 16.0 | . 42 South Dakota | 110.0 | 37.0 | 21.0 | 13.0 | 3.0 | 12.0 | 8.0 | 4.0 | 0.0 | ... | 21.0 | 0.0 | 0.0 | 6.0 | 0.0 | 5.0 | 0.0 | 5.0 | 2.0 | 3.0 | . 43 Tennessee | 1032.0 | 270.0 | 22.0 | 186.0 | 62.0 | 87.0 | 51.0 | 7.0 | 29.0 | ... | 185.0 | 3.0 | 19.0 | 19.0 | 7.0 | 41.0 | 8.0 | 20.0 | 11.0 | 57.0 | . 44 Texas | 4068.0 | 905.0 | 99.0 | 609.0 | 197.0 | 424.0 | 177.0 | 101.0 | 146.0 | ... | 880.0 | 34.0 | 77.0 | 92.0 | 84.0 | 184.0 | 23.0 | 91.0 | 114.0 | 181.0 | . 45 Utah | 508.0 | 116.0 | 8.0 | 85.0 | 23.0 | 54.0 | 27.0 | 13.0 | 14.0 | ... | 99.0 | 1.0 | 15.0 | 12.0 | 12.0 | 15.0 | 0.0 | 6.0 | 16.0 | 22.0 | . 46 Virginia | 1513.0 | 265.0 | 51.0 | 157.0 | 57.0 | 145.0 | 56.0 | 29.0 | 60.0 | ... | 291.0 | 11.0 | 22.0 | 13.0 | 33.0 | 63.0 | 6.0 | 21.0 | 43.0 | 79.0 | . 47 Vermont | 61.0 | 25.0 | 9.0 | 15.0 | 1.0 | 6.0 | 6.0 | 0.0 | 0.0 | ... | 7.0 | 0.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 3.0 | . 48 Washington | 914.0 | 256.0 | 51.0 | 143.0 | 62.0 | 110.0 | 49.0 | 24.0 | 37.0 | ... | 171.0 | 5.0 | 24.0 | 24.0 | 10.0 | 27.0 | 3.0 | 12.0 | 26.0 | 40.0 | . 49 Wisconsin | 1130.0 | 311.0 | 51.0 | 183.0 | 77.0 | 121.0 | 60.0 | 18.0 | 43.0 | ... | 176.0 | 0.0 | 19.0 | 17.0 | 13.0 | 37.0 | 9.0 | 16.0 | 31.0 | 34.0 | . 50 West Virginia | 183.0 | 52.0 | 10.0 | 29.0 | 13.0 | 17.0 | 7.0 | 2.0 | 8.0 | ... | 32.0 | 2.0 | 0.0 | 5.0 | 2.0 | 4.0 | 4.0 | 2.0 | 6.0 | 7.0 | . 51 Wyoming | 101.0 | 28.0 | 3.0 | 25.0 | 0.0 | 18.0 | 7.0 | 7.0 | 4.0 | ... | 12.0 | 0.0 | 0.0 | 5.0 | 0.0 | 2.0 | 0.0 | 0.0 | 3.0 | 2.0 | . 52 rows × 30 columns . . Index([&#39;Unnamed: 0&#39;, &#39;Unnamed: 1&#39;, &#39;Life sciences&#39;, &#39;Unnamed: 3&#39;, &#39;Unnamed: 4&#39;, &#39;Unnamed: 5&#39;, &#39;Physical sciences and earth sciences&#39;, &#39;Unnamed: 7&#39;, &#39;Unnamed: 8&#39;, &#39;Unnamed: 9&#39;, &#39;Mathematics and computer sciences&#39;, &#39;Unnamed: 11&#39;, &#39;Unnamed: 12&#39;, &#39;Psychology and social sciences &#39;, &#39;Unnamed: 14&#39;, &#39;Unnamed: 15&#39;, &#39;Unnamed: 16&#39;, &#39;Unnamed: 17&#39;, &#39;Unnamed: 18&#39;, &#39;Unnamed: 19&#39;, &#39;Unnamed: 20&#39;, &#39;Unnamed: 21&#39;, &#39;Unnamed: 22&#39;, &#39;Unnamed: 23&#39;, &#39;Unnamed: 24&#39;, &#39;Unnamed: 25&#39;, &#39;Unnamed: 26&#39;, &#39;Unnamed: 27&#39;, &#39;Unnamed: 28&#39;, &#39;Unnamed: 29&#39;], dtype=&#39;object&#39;) . df_final = df1[[&#39;Unnamed: 0&#39;, &#39;Unnamed: 1&#39;, &#39;Life sciences&#39;, &#39;Physical sciences and earth sciences&#39;, &#39;Mathematics and computer sciences&#39;, &#39;Psychology and social sciences &#39;, &#39;Unnamed: 20&#39; ]] . Unnamed: 0 Unnamed: 1 Life sciences Physical sciences and earth sciences Mathematics and computer sciences Psychology and social sciences Unnamed: 20 . 0 Alaska | 52.0 | 10.0 | 20.0 | 0.0 | 17.0 | 3.0 | . 1 Alabama | 707.0 | 188.0 | 59.0 | 48.0 | 89.0 | 131.0 | . 2 Arkansas | 202.0 | 75.0 | 17.0 | 10.0 | 19.0 | 33.0 | . 3 Arizona | 801.0 | 133.0 | 110.0 | 51.0 | 156.0 | 141.0 | . 4 California | 6105.0 | 1300.0 | 841.0 | 495.0 | 1132.0 | 1151.0 | . df_final.columns = [&#39;State&#39;, &quot;All Fields&quot; , &#39;Life Sciences&#39; , &#39;Physical Sciences and Earth Sciences&#39; , &#39;Mathematics and Computer Sciences&#39; , &#39;Psychology and Social Sciences&#39; , &#39;Engineering&#39;] . State All Fields Life Sciences Physical Sciences and Earth Sciences Mathematics and Computer Sciences Psychology and Social Sciences Engineering . 0 Alaska | 52.0 | 10.0 | 20.0 | 0.0 | 17.0 | 3.0 | . 1 Alabama | 707.0 | 188.0 | 59.0 | 48.0 | 89.0 | 131.0 | . 2 Arkansas | 202.0 | 75.0 | 17.0 | 10.0 | 19.0 | 33.0 | . 3 Arizona | 801.0 | 133.0 | 110.0 | 51.0 | 156.0 | 141.0 | . 4 California | 6105.0 | 1300.0 | 841.0 | 495.0 | 1132.0 | 1151.0 | . 5 Colorado | 1005.0 | 212.0 | 155.0 | 67.0 | 128.0 | 206.0 | . 6 Connecticut | 748.0 | 196.0 | 104.0 | 60.0 | 129.0 | 97.0 | . 7 District of Columbia | 623.0 | 55.0 | 37.0 | 24.0 | 207.0 | 78.0 | . 8 Delaware | 238.0 | 59.0 | 24.0 | 19.0 | 45.0 | 69.0 | . 9 Florida | 2336.0 | 490.0 | 259.0 | 145.0 | 409.0 | 419.0 | . 10 Georgia | 1492.0 | 357.0 | 129.0 | 99.0 | 216.0 | 360.0 | . 11 Hawaii | 189.0 | 44.0 | 29.0 | 4.0 | 61.0 | 11.0 | . 12 Iowa | 715.0 | 150.0 | 79.0 | 72.0 | 82.0 | 152.0 | . 13 Idaho | 103.0 | 32.0 | 14.0 | 5.0 | 15.0 | 16.0 | . 14 Illinois | 2534.0 | 478.0 | 267.0 | 193.0 | 445.0 | 435.0 | . 15 Indiana | 1572.0 | 309.0 | 195.0 | 119.0 | 221.0 | 329.0 | . 16 Kansas | 530.0 | 148.0 | 44.0 | 23.0 | 111.0 | 74.0 | . 17 Kentucky | 497.0 | 138.0 | 22.0 | 35.0 | 75.0 | 48.0 | . 18 Louisiana | 607.0 | 157.0 | 68.0 | 48.0 | 90.0 | 74.0 | . 19 Massachusetts | 2879.0 | 706.0 | 372.0 | 177.0 | 474.0 | 597.0 | . 20 Maryland | 1295.0 | 439.0 | 141.0 | 118.0 | 205.0 | 225.0 | . 21 Maine | 56.0 | 15.0 | 11.0 | 1.0 | 9.0 | 11.0 | . 22 Michigan | 1906.0 | 385.0 | 206.0 | 118.0 | 345.0 | 394.0 | . 23 Minnesota | 1374.0 | 397.0 | 66.0 | 53.0 | 362.0 | 128.0 | . 24 Missouri | 1022.0 | 259.0 | 108.0 | 55.0 | 152.0 | 171.0 | . 25 Mississippi | 460.0 | 107.0 | 48.0 | 20.0 | 76.0 | 51.0 | . 26 Montana | 119.0 | 36.0 | 15.0 | 11.0 | 14.0 | 9.0 | . 27 North Carolina | 1833.0 | 545.0 | 194.0 | 155.0 | 247.0 | 316.0 | . 28 North Dakota | 181.0 | 46.0 | 10.0 | 8.0 | 32.0 | 30.0 | . 29 Nebraska | 363.0 | 143.0 | 32.0 | 27.0 | 46.0 | 44.0 | . 30 New Hampshire | 158.0 | 60.0 | 32.0 | 10.0 | 17.0 | 17.0 | . 31 New Jersey | 1115.0 | 209.0 | 145.0 | 100.0 | 179.0 | 194.0 | . 32 New Mexico | 299.0 | 45.0 | 44.0 | 21.0 | 43.0 | 74.0 | . 33 Nevada | 200.0 | 21.0 | 20.0 | 11.0 | 44.0 | 34.0 | . 34 New York | 4064.0 | 859.0 | 411.0 | 302.0 | 835.0 | 567.0 | . 35 Ohio | 2028.0 | 440.0 | 260.0 | 113.0 | 283.0 | 410.0 | . 36 Oklahoma | 524.0 | 137.0 | 46.0 | 25.0 | 73.0 | 70.0 | . 37 Oregon | 572.0 | 183.0 | 95.0 | 52.0 | 80.0 | 71.0 | . 38 Pennsylvania | 2628.0 | 589.0 | 248.0 | 206.0 | 356.0 | 545.0 | . 39 Puerto Rico | 84.0 | 8.0 | 4.0 | 1.0 | 43.0 | 4.0 | . 40 Rhode Island | 322.0 | 67.0 | 47.0 | 37.0 | 58.0 | 39.0 | . 41 South Carolina | 506.0 | 100.0 | 59.0 | 32.0 | 65.0 | 141.0 | . 42 South Dakota | 110.0 | 37.0 | 12.0 | 10.0 | 19.0 | 21.0 | . 43 Tennessee | 1032.0 | 270.0 | 87.0 | 52.0 | 153.0 | 185.0 | . 44 Texas | 4068.0 | 905.0 | 424.0 | 296.0 | 553.0 | 880.0 | . 45 Utah | 508.0 | 116.0 | 54.0 | 49.0 | 82.0 | 99.0 | . 46 Virginia | 1513.0 | 265.0 | 145.0 | 103.0 | 277.0 | 291.0 | . 47 Vermont | 61.0 | 25.0 | 6.0 | 4.0 | 7.0 | 7.0 | . 48 Washington | 914.0 | 256.0 | 110.0 | 68.0 | 116.0 | 171.0 | . 49 Wisconsin | 1130.0 | 311.0 | 121.0 | 75.0 | 138.0 | 176.0 | . 50 West Virginia | 183.0 | 52.0 | 17.0 | 11.0 | 31.0 | 32.0 | . 51 Wyoming | 101.0 | 28.0 | 18.0 | 5.0 | 18.0 | 12.0 | . df_exports = pd.read_csv(&#39;https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv&#39;) df_codes = df_final.merge(df_exports, left_on = &#39;State&#39;, right_on = &#39;state&#39;, how = &#39;left&#39;) df_codes.head() . State All Fields Life Sciences Physical Sciences and Earth Sciences Mathematics and Computer Sciences Psychology and Social Sciences Engineering code state category ... dairy fruits fresh fruits proc total fruits veggies fresh veggies proc total veggies corn wheat cotton . 0 Alaska | 52.0 | 10.0 | 20.0 | 0.0 | 17.0 | 3.0 | AK | Alaska | state | ... | 0.19 | 0.0 | 0.0 | 0.00 | 0.6 | 1.0 | 1.56 | 0.0 | 0.0 | 0.00 | . 1 Alabama | 707.0 | 188.0 | 59.0 | 48.0 | 89.0 | 131.0 | AL | Alabama | state | ... | 4.06 | 8.0 | 17.1 | 25.11 | 5.5 | 8.9 | 14.33 | 34.9 | 70.0 | 317.61 | . 2 Arkansas | 202.0 | 75.0 | 17.0 | 10.0 | 19.0 | 33.0 | AR | Arkansas | state | ... | 3.53 | 2.2 | 4.7 | 6.88 | 4.4 | 7.1 | 11.45 | 69.5 | 114.5 | 665.44 | . 3 Arizona | 801.0 | 133.0 | 110.0 | 51.0 | 156.0 | 141.0 | AZ | Arizona | state | ... | 105.48 | 19.3 | 41.0 | 60.27 | 147.5 | 239.4 | 386.91 | 7.3 | 48.7 | 423.95 | . 4 California | 6105.0 | 1300.0 | 841.0 | 495.0 | 1132.0 | 1151.0 | CA | California | state | ... | 929.95 | 2791.8 | 5944.6 | 8736.40 | 803.2 | 1303.5 | 2106.79 | 34.6 | 249.3 | 1064.95 | . 5 rows × 24 columns . df_codes = df_codes.iloc[:,0:8] df_codes.to_csv(&#39;/Users/dapoadegbile/Documents/Biostat 823/Homework/DoctoratesbyStateandDegree.csv&#39;, index_label = False) . State All Fields Life Sciences Physical Sciences and Earth Sciences Mathematics and Computer Sciences Psychology and Social Sciences Engineering code . 0 Alaska | 52.0 | 10.0 | 20.0 | 0.0 | 17.0 | 3.0 | AK | . 1 Alabama | 707.0 | 188.0 | 59.0 | 48.0 | 89.0 | 131.0 | AL | . 2 Arkansas | 202.0 | 75.0 | 17.0 | 10.0 | 19.0 | 33.0 | AR | . 3 Arizona | 801.0 | 133.0 | 110.0 | 51.0 | 156.0 | 141.0 | AZ | . 4 California | 6105.0 | 1300.0 | 841.0 | 495.0 | 1132.0 | 1151.0 | CA | . Below are the plots used the in dashboard and the code that accompanies it. Using a choropleth map, we can cleanly see how the popularity of each field varies from state to state. The total number of schools is represented by the color gradient, and you can filter the fields to see which fields are more popular within each state. Additionally I added a bar chart that shows each fields popularity in each stat as another means of comparison. . From the dashboard we can see that California gave out the most doctorate degrees in 2017, followed by Texas and New York. Additionally LIfe Sciences is the hottest field, while Engineering and Psychology and Social Sciences are a close second and third. . import plotly.graph_objects as go for col in df_codes.columns: df_codes[col] = df_codes[col].astype(str) # df_codes[&#39;text&#39;] = df_codes[&#39;All Fields&#39;] + &#39;&lt;br&gt;&#39; + # &#39;Life Sciences &#39; + df_codes[&#39;Life Sciences&#39;] + &#39; Physical Sciences and Earth Sciences &#39; + df_codes[&#39;Physical Sciences and Earth Sciences&#39;] + &#39;&lt;br&gt;&#39; + # &#39;Mathematics and Computer Sciences &#39; + df_codes[&#39;Mathematics and Computer Sciences&#39;] + &#39; Psychology and Social Sciences &#39; + df_codes[&#39;Psychology and Social Sciences&#39;] + &#39;&lt;br&gt;&#39; + # &#39;Engineering &#39; + df_codes[&#39;Engineering&#39;] fig = go.Figure(data=go.Choropleth( locations= df_codes[&#39;code&#39;], # Spatial coordinates z = df_codes[&#39;All Fields&#39;].astype(float), # Data to be color-coded locationmode = &#39;USA-states&#39;, # set of locations match entries in `locations` colorscale = &#39;Greens&#39;, # hover_name = &quot;State&quot;, hover_data = &quot;All Fields&quot;, text=df_codes[&#39;State&#39;], # hover text colorbar_title = &quot;Number of Doctorates&quot;, )) fig.update_layout( title_text = &#39;Number of Doctorates by State&#39;, geo_scope=&#39;usa&#39;, # limit map scope to USA ) fig.show() . fig = go.Figure(go.Bar( y=(df_codes[&#39;All Fields&#39;]).astype(float), x= df_codes[&#39;State&#39;], marker_color = &#39;indianred&#39;)) fig.update_layout(xaxis_tickangle=-90) fig.show() .",
            "url": "https://dapoade.github.io/fastpages/2021/10/24/Interactive-Dashboard.html",
            "relUrl": "/2021/10/24/Interactive-Dashboard.html",
            "date": " • Oct 24, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Creating  Visualizations",
            "content": "By: Dapo Adegbile . import plotly.io as pio pio.renderers.default= &#39;notebook_connected&#39; from IPython.display import display, HTML from io import StringIO js = &#39;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js&quot; integrity=&quot;sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&#39; display(HTML(js)) . . Load Packages . import numpy as np import pandas as pd import shapefile as shp import matplotlib.pyplot as plt import seaborn as sns import plotly import plotly.express as px . . Load in Data . malaria_deaths = pd.read_csv(&#39;./malaria_deaths.csv&#39;) malaria_deaths_age = pd.read_csv(&#39;./malaria_deaths_age.csv&#39;) malaria_inc = pd.read_csv(&#39;./malaria_inc.csv&#39;) . . Data Cleaning . malaria_deaths.columns = [&#39;Entity&#39;, &#39;Code&#39;, &#39;Year&#39;, &#39;Deaths&#39;] malaria_deaths.head() . Entity Code Year Deaths . 0 Afghanistan | AFG | 1990 | 6.802930 | . 1 Afghanistan | AFG | 1991 | 6.973494 | . 2 Afghanistan | AFG | 1992 | 6.989882 | . 3 Afghanistan | AFG | 1993 | 7.088983 | . 4 Afghanistan | AFG | 1994 | 7.392472 | . . malaria_deaths_age.head() malaria = malaria_deaths_age.groupby([&#39;entity&#39;, &#39;year&#39;]).apply(lambda a: a[:]) malaria . Unnamed: 0 entity code year age_group deaths . entity year . Afghanistan 1990 0 1 | Afghanistan | AFG | 1990 | Under 5 | 184.606435 | . 6156 6157 | Afghanistan | AFG | 1990 | 70 or older | 10.728850 | . 12312 12313 | Afghanistan | AFG | 1990 | 5-14 | 53.352844 | . 18468 18469 | Afghanistan | AFG | 1990 | 15-49 | 414.709676 | . 24624 24625 | Afghanistan | AFG | 1990 | 50-69 | 60.541746 | . ... ... ... ... | ... | ... | ... | ... | ... | . Zimbabwe 2016 6155 6156 | Zimbabwe | ZWE | 2016 | Under 5 | 745.340029 | . 12311 12312 | Zimbabwe | ZWE | 2016 | 70 or older | 66.572213 | . 18467 18468 | Zimbabwe | ZWE | 2016 | 5-14 | 177.953936 | . 24623 24624 | Zimbabwe | ZWE | 2016 | 15-49 | 453.902190 | . 30779 30780 | Zimbabwe | ZWE | 2016 | 50-69 | 97.402058 | . 30780 rows × 6 columns . . Background: . In this blog post I&#39;ve been tasked with analyzing malaria data through three informative visualizations. The data can be found in the following github: . https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13. . To make my visualizations, I decided to use plotly because of my familiarity and it&#39;s compatibility with Jupyter notebooks. . Malaria Deaths by Country . The first visualization I created color codes the amount of malaria deaths (per 100,000 people) by country from 1990 - 2016 by year. From this graphic we can see that most malaria deaths are in Africa, while a smaller concentration of malaria deaths can be found in Southeast Asia. Additionally as the years go on, Malaria deaths (per 100,000 people) experience significant decrease. The code used to generate the plot can be found below. . malaria_deaths_plot = px.choropleth(malaria_deaths, locations = &#39;Code&#39;, color = &#39;Deaths&#39;, color_continuous_scale= &quot;twilight&quot;, animation_frame = &#39;Year&#39;, height = 750, width = 1000, hover_name = &#39;Code&#39; ) malaria_deaths_plot.update_layout( geo = dict( showcoastlines = False, lataxis_showgrid = True, lonaxis_showgrid = True, projection_type = &#39;natural earth&#39;), hoverlabel = dict( bgcolor = &#39;white&#39;, font_size = 16 ) ) #fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0}) malaria_deaths_plot.show() #HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(malaria_deaths_plot.to_html()) #HTML(malaria_deaths_plot.to_html(include_plotlyjs=&#39;cdn&#39;)) . Calculate the average amount of deaths per age group, per year. . malaria_deaths_age = malaria_deaths_age[[&#39;entity&#39;, &#39;code&#39; , &#39;year&#39; , &#39;age_group&#39; , &#39;deaths&#39;]] malaria_deaths_age_mean = malaria_deaths_age.groupby([&#39;age_group&#39;, &#39;year&#39;]).mean(&#39;deaths&#39;).reset_index() malaria_deaths_age_mean.head(12) . age_group year deaths . 0 15-49 | 1990 | 972.488397 | . 1 15-49 | 1991 | 1027.454620 | . 2 15-49 | 1992 | 1054.176987 | . 3 15-49 | 1993 | 1093.039510 | . 4 15-49 | 1994 | 1130.813551 | . 5 15-49 | 1995 | 1178.852962 | . 6 15-49 | 1996 | 1231.006569 | . 7 15-49 | 1997 | 1265.392051 | . 8 15-49 | 1998 | 1329.579833 | . 9 15-49 | 1999 | 1380.716326 | . 10 15-49 | 2000 | 1435.443300 | . 11 15-49 | 2001 | 1503.427846 | . . Malaria Deaths by Age Group . This next graphic displays the malaria death rate by age group by year. From the graphic we can see that children from under 5 are most prone to malaria mortality, while adults aged 70 or older are less susceptible. You can hover over the different years on the graph to get a more descriptive view of the respective death rates. The code used to generate the plot can be found below. . malaria_age = px.line(malaria_deaths_age_mean , x = &#39;year&#39;, y = &#39;deaths&#39;, log_y = True, color = &#39;age_group&#39;, title = &#39;Average Malaria Deaths Per 100,000 People Vs. Age Groups &amp; Years (1990 - 2016)&#39;, width = 800, height = 600) malaria_age.update_traces(mode=&quot;markers+lines&quot;, hovertemplate=&#39;%{y:.2f}&#39;) malaria_age.update_layout(hovermode=&quot;x&quot;) #malaria_age.update_layout(margin={&quot;r&quot;:150,&quot;t&quot;:200,&quot;l&quot;:200,&quot;b&quot;:50}) malaria_age.show() #HTML(malaria_age.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(malaria_age.to_html()) . Incidents by Country . For my last graphic i decided to make a graphic that highlights Malaria cases per 1,000 people in countries worldwide from 2000 - 2015. A large number of incidents are concentrated in Africa and South East Asia. It is worth noting that many countries decrease their incidence rate over time. . malaria_incidents = px.scatter_geo(malaria_inc, locations=&quot;Code&quot;, size = &#39;Incidents&#39;, animation_frame = &#39;Year&#39;, hover_name = &#39;Entity&#39;, title = &#39;Malaria Incidents Per 100,000 People in Africa Vs. Years (2000 - 2015)&#39;, width = 1000, height = 700, size_max = 30, opacity = .75 ) malaria_incidents.update_layout( geo = dict( showcoastlines = False, lataxis_showgrid=True, lonaxis_showgrid=True, projection_type=&quot;natural earth&quot;) ) #malaria_incidents.update_layout(margin={&quot;r&quot;: 0,&quot;t&quot;: 0,&quot;l&quot;: 0,&quot;b&quot;:0}) malaria_incidents.show() #HTML(malaria_incidents.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(malaria_incidents.to_html()) .",
            "url": "https://dapoade.github.io/fastpages/2021/10/01/VISUALIZATIONS.html",
            "relUrl": "/2021/10/01/VISUALIZATIONS.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "NUMBER THEORY",
            "content": "Find the first 10-digit prime in the decimal expansion of 17&#960;. . import math from mpmath import mp . My approach to this problem can be broken down into three parts (or helper functions): . 1. Create a function that expands the decimals of 17pi to a given precision. . 2. Write a function that checks if a specified value is prime. . 3. Write a function that creates a 10 digit sliding window and checks if each window is contains a prime number. . The function below returns 17pi to the specified precision. To generate a large decimal expansion of a number, I decided to use the &#39;mpmath&#39; library. . https://mpmath.org/doc/current/basics.html . The input for the function are the number of digits (num_digits) we want to expand the number to (after the decimal) and the relevant multiplier for this problem. . def digits_after_decimal(num_digits, number, multiplier): &quot;&quot;&quot; Function to generate a specific amount of numbers after the decimal of a multiplier (17) * pi &quot;&quot;&quot; mp.dps = num_digits a = (number * multiplier) expanded = mp.nstr(a, num_digits) expanded = expanded[2:].replace(&#39;.&#39;, &#39;&#39;) return expanded . digits_after_decimal(500, mp.pi, 17) . &#39;407075111026485053864937515751549031351879789376798956574058069232878906865552976676592030815990155696517470725799213000595358362359897939331109938184178996654829745932954858794513958590132233816493395289786586320868584184086019974375313809610432455476025637698825926377723553019627691323424235401653317979112307364998972985855656368097319559161194254174036120192619019329947930863530498183005697360361973596217913063202567163995492854400482787015317265860459366742644982057796323150874949111203135&#39; . . Unit Test . print(&#39;The 6 digit expansion of numbers after the decimal of pi are &#39;14159265 &#39;&#39;) print(&#39;My function generated 6 digit expansion pi is &#39; + str(digits_after_decimal(9, mp.pi, 1))) . The 6 digit expansion of numbers after the decimal of pi are &#39;14159265&#39; My function generated 6 digit expansion pi is 14159265 . The next helper function I needed was to check whether or not a number is prime. To do this, checked to see if there are any factors between 2 and the square root of the number of interest. I looped from 2 to the square root of the number because if a number n is not a prime, it can be factored into two factors a and b: . #### n = a * b | . Because a and b can&#39;t both be greater than the square root of n, since then the product a * b would be greater than sqrt(n) * sqrt(n) = n. So in any factorization of n, at least one of the factors must be smaller than the square root of n, and if we can&#39;t find any factors less than or equal to the square root, n must be a prime. . If the number is divisible by the factor, then I returned False. If the number isn&#39;t divisible by the factor, then I increased the factor by 1 and the loop continues until a either a factor is found or once the factors we are testing become greater than or equal to the square root of our number of interest. . def is_prime(n): if n &lt;= 1: return False max_div = math.floor(math.sqrt(n)) for i in range(2, 1 + max_div): if n % i == 0: return False return True . Unit Test . def test_is_prime(): assert is_prime(131) == True assert is_prime(7) == True assert is_prime(16) == False assert is_prime(169) == False print(&quot;Passed!&quot;) test_is_prime() . Passed! . The last helper function creates a sliding window of 10 digits to traverse the string and determine if the 10 digit sequence/number is prime. . def prime_digits(num_after_dec): &quot;&quot;&quot;A function to find the first 10 digit sequence that&quot;&quot;&quot; for i in range(len(num_after_dec) - 10): digits = num_after_dec[i:i+10] if is_prime(int(digits)): print(f&quot;{digits} is the first 10 digit prime in the decimal expansion&quot;) return digits . Final Solution . Unit Test for e . e_digits = digits_after_decimal(500, mp.e, 1) prime_digits(e_digits) . 7427466391 is the first 10 digit prime in the decimal expansion . &#39;7427466391&#39; . Final solution for 17 Pi . pi_digits = digits_after_decimal(500, mp.pi, 17) prime_digits(pi_digits) . 8649375157 is the first 10 digit prime in the decimal expansion . &#39;8649375157&#39; .",
            "url": "https://dapoade.github.io/fastpages/2021/09/17/NUMBER-THEORY.html",
            "relUrl": "/2021/09/17/NUMBER-THEORY.html",
            "date": " • Sep 17, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Euler Project Problem Set",
            "content": "By Dapo Adegbile . The purpose of this post is to outline my solutions for 3 problems from Project Euler (https://projecteuler.net/archives). One problems was solved buy less than 500,000 people, the next problem was solved by less than 100,000 people, and the last problem was solved by less than 25,000 people. . Problem 6: Sum square difference . Solved By - 496334 . https://projecteuler.net/problem=6 . The sum of the squares of the first ten natural numbers is, $$ 1^{2}+2^{2}+ ldots+10^{2}=385 $$ The square of the sum of the first ten natural numbers is, $$ (1+2+ ldots+10)^{2}=55^{2}=3025 $$ Hence the difference between the sum of the squares of the first ten natural numbers and the square of the sum is $3025-385=2640$ Find the difference between the sum of the squares of the first one hundred natural numbers and the square of the sum. . Find the difference between the sum of the squares of the first one hundred natural numbers and the square of the sum. . My approach for this problem was to first generate a list of numbers from 1-100 so I can perform the necessary calculation on each number in the list. Once generated, to find the sum of the squares, I squared each number in the list and then added them together. Next, to get the square of the sum, I added all of the numbers in the original list, and then squared the sum. Lastly I took the difference between the sum of the squares and the square of the sum and arrived at 25164150 for my solution. . def sum_square_diff(num): &quot;&quot;&quot; Returns the difference between the sum of the squares and the square of the sum for the first hundred natural numbers &quot;&quot;&quot; numbers = list(range(1,num+1)) squared_numbers = [number ** 2 for number in numbers] sum_sq1 = sum(squared_numbers) sum_sq2 = (sum(numbers))**2 diff = abs(sum_sq1 - sum_sq2) return diff . . sum_square_diff(100) . 25164150 . . Problem 36: Double-base Palindromes . Solved By - 89573 . https://projecteuler.net/problem=36 . The decimal number, $585=1001001001_{2}$ (binary), is palindromic in both bases. Find the sum of all numbers, less than one million, which are palindromic in base 10 and base $2 .$ (Please note that the palindromic number, in either base, may not include leading zeros.) . For this problem my first instict was to create a list of of all the natural numbers that are palindromic in base 10. Once created, I looped through said list to check if they are palindromic in base 2. If the number is palindromic in base 2, I added it to a dictionary with the key being the base 2 number, and the value being the base 10 number. Once the dictionary is completed I added all of the values (base 10 numbers) and got the sum of the numbers that are palindromic in base 10 and base 2. . def palindrome_sum(num): &quot;&quot;&quot; Returns a sum of all the natural numbers less than one million that are palindromic in base 10 and base 2&quot;&quot;&quot; palindrome_list = [] # create a list natural numbers in base 10 that are palindrome for i in range(1,num + 1): i = str(i) rev = i[::-1] # reverse the number if i == rev: # if the number is a palindrome, append it to the list palindrome_list.append(i) # convert strings in list to integers palindrome_list = list(map(int, palindrome_list)) match = dict() # loop over palindromic natural numbers to see if binary value is palindromic for a in palindrome_list: binary = bin(a)[2:] # removed the &#39;0b&#39; at the beginning of binary string rev_bin = binary[::-1] if binary == rev_bin: match[binary] = a match return sum(match.values()) . . palindrome_sum(1_000_000) . 872187 . . Problem 112: Bouncy Numbers . Solved By - 24437 . https://projecteuler.net/problem=112 . Working from left-to-right if no digit is exceeded by the digit to its left it is called an increasing number; for example, $134468 .$ . Similarly if no digit is exceeded by the digit to its right it is called a decreasing number; for example, $66420 .$ . We shall call a positive integer that is neither increasing nor decreasing a &quot;bouncy&quot; number; for example, $155349 .$ . Clearly there cannot be any bouncy numbers below one-hundred, but just over half of the numbers below one-thousand (525) are bouncy. In fact, the least number for which the proportion of bouncy numbers first reaches $50 %$ is 538 . . Surprisingly, bouncy numbers become more and more common and by the time we reach 21780 the proportion of bouncy numbers is equal to $90 %$. . Find the least number for which the proportion of bouncy numbers is exactly $99 %$. . To start this problem I determined that I needed a function to determine whether or not a number is bouncy. To check if a number is bouncy I had to make sure that the number was neither increasing nor decreasing. . After creating this function, I&#39;d loop through numbers and if a number was bouncy, I&#39;d add it to a list. To calculate the proportion of bouncy numbers, I&#39;d divide the length of the current list by current number being evaluated. The loop ends when the percent becomes 99%. . def is_bouncy(n): &quot;&quot;&quot; returns whether or not a number is &#39;bouncy&#39; &quot;&quot;&quot; return sorted(str(n)) != list(str(n)) and sorted(str(n)) != list(str(n))[::-1] def bouncy_99(): &quot;&quot;&quot; Finds the least number for which the proportion of bouncy numbers is exactly 99%.&quot;&quot;&quot; percent = 0 i = 0 bouncy_list = [] while percent &lt; .99 : i += 1 if is_bouncy(i): bouncy_list.append(i) percent = len(bouncy_list) / i return i, percent . . bouncy_99() . (1587000, 0.99) . .",
            "url": "https://dapoade.github.io/fastpages/2021/09/03/Euler-Project-Problem-Set.html",
            "relUrl": "/2021/09/03/Euler-Project-Problem-Set.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://dapoade.github.io/fastpages/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://dapoade.github.io/fastpages/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://dapoade.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dapoade.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}